{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441246fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Torch CUDA version: None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from TetrisGym_0517 import TetrisGym\n",
    "from cnn_dqn import CNNAgent\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA version:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7be973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Hyper‑parameters \"\"\"\n",
    "# board settings\n",
    "BOARD_WIDTH = 10\n",
    "BOARD_HEIGHT = 20\n",
    "\n",
    "# bellman update settings\n",
    "ALPHA = 0.001  # learning rate\n",
    "GAMMA = 0.99  # discount factor\n",
    "\n",
    "# epsilon-greedy settings\n",
    "EPSILON = 1.0  # exploration rate (starting value)\n",
    "EPSILON_MIN = 0.1  # minimum epsilon\n",
    "EPSILON_DECAY = 0.9995\n",
    "\n",
    "NUM_EPISODES = 100_000 # 1_000_000\n",
    "MAX_STEPS = 1_000\n",
    "\n",
    "# Batch parameters\n",
    "MEMORY_SIZE= 30_000  # size of memory to sample batches from\n",
    "BATCH_SIZE = 64  # mini-batch size for replay(), used to perform a training update\n",
    "TARGET_UPDATE_FREQ = 10  # episodes between target-net sync\n",
    "\n",
    "# Train on CPU OR GPU?\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", DEVICE)\n",
    "\n",
    "# Saving logistics\n",
    "SAVE_PATH = \"cnn_dqn_checkpoints/latest.pth\"\n",
    "\n",
    "\n",
    "env = TetrisGym(width=BOARD_WIDTH, height=BOARD_HEIGHT, max_steps=MAX_STEPS)\n",
    "agent = CNNAgent(\n",
    "    board_width=BOARD_WIDTH, board_height=BOARD_HEIGHT,\n",
    "    alpha=ALPHA, gamma=GAMMA,\n",
    "    eps_start=EPSILON, eps_min=EPSILON_MIN, eps_decay=EPSILON_DECAY,\n",
    "    memory_size=MEMORY_SIZE, batch_size=BATCH_SIZE, target_sync=TARGET_UPDATE_FREQ,\n",
    "    device=DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85987b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DQN:   0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DQN:   0%|          | 37/100000 [00:19<15:43:14,  1.77it/s][E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "DQN:   0%|          | 37/100000 [00:19<14:51:55,  1.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_STEPS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m agent\u001b[38;5;241m.\u001b[39msave_agent(SAVE_PATH)\n",
      "File \u001b[0;32m~/Documents/GitHub/tetris_ai/run_on_cluster/dqn/cnn_dqn.py:223\u001b[0m, in \u001b[0;36mCNNAgent.train\u001b[0;34m(self, env, episodes, max_steps)\u001b[0m\n\u001b[1;32m    220\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_obs(next_raw_obs)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memorize(state, action, reward, next_state, done)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m    226\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/tetris_ai/run_on_cluster/dqn/cnn_dqn.py:185\u001b[0m, in \u001b[0;36mCNNAgent._replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Updates the main model's weights \u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 185\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# back propagation\u001b[39;00m\n\u001b[1;32m    186\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)  \u001b[38;5;66;03m# rescales gradients s.t. global l2-norm<=max_norm \u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(env, episodes=NUM_EPISODES, max_steps=MAX_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22649b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyper‑parameters \"\"\"\n",
    "# board settings\n",
    "BOARD_WIDTH = 10\n",
    "BOARD_HEIGHT = 20\n",
    "\n",
    "# bellman update settings\n",
    "ALPHA = 0.001  # learning rate\n",
    "GAMMA = 0.99  # discount factor\n",
    "\n",
    "# epsilon-greedy settings\n",
    "EPSILON = 1.0  # will be updated when model is loaded\n",
    "EPSILON_MIN = 0.1  # minimum epsilon\n",
    "EPSILON_DECAY = 0.9995\n",
    "\n",
    "NUM_EPISODES = 10_000 #1_000_000\n",
    "MAX_STEPS = 1_000\n",
    "\n",
    "# Batch parameters\n",
    "MEMORY_SIZE= 10_000  # size of memory to sample batches from\n",
    "BATCH_SIZE = 32 # mini-batch size for replay(), used to perform a training update\n",
    "TARGET_UPDATE_FREQ = 10  # episodes between target-net sync\n",
    "\n",
    "# Train on CPU OR GPU?\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", DEVICE)\n",
    "\n",
    "# Saving logistics\n",
    "LOAD_PATH = \"cnn_dqn_checkpoints/latest.pth\"\n",
    "SAVE_PATH = \"cnn_dqn_checkpoints/latest.pth\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
